# ü•ì BaconAlgo ‚Äî Guide de D√©ploiement Production

## Pr√©requis
- Docker Desktop install√©
- Compte Cloudflare (gratuit)
- Domaine baconalgo.com configur√© sur Cloudflare DNS

## Installation rapide

### 1. Cloner le repo
```bash
git clone https://github.com/germain85ok/BaconAlgo.git
cd BaconAlgo
```

### 2. Configurer les variables d'environnement
```bash
cp .env.example .env
# √âditer .env avec tes vraies cl√©s API
```

### 3. Lancer la production
```bash
chmod +x deploy/*.sh
./deploy/setup-production.sh
```

### 4. Configurer Cloudflare Tunnel
```bash
./deploy/cloudflare-tunnel-setup.sh
```

### 5. C'est en ligne!
Visite **https://baconalgo.com** ü•ì

---

## Architecture

### Serveur Production
- **CPU**: AMD Ryzen 7 7800X3D (8 cores / 16 threads, 96MB V-Cache)
- **RAM**: 32 GB DDR5
- **GPU**: NVIDIA RTX 4070 (12 GB VRAM, 5888 CUDA cores)
- **SSD**: WD BLACK SN850X 2TB NVMe
- **OS**: Windows 11 Pro (WSL2 disponible)
- **Internet**: 447 Mbps down / 56 Mbps up / 12ms ping

### Services Docker

#### ü¶Ä Backend (Rust Axum)
- Port: 8080
- CPU: 4 cores max
- RAM: 4GB max
- Rust high-performance API
- Scanner Rayon multithread√©

#### üé® Station (SvelteKit Node SSR)
- Port: 5173
- CPU: 2 cores max
- RAM: 2GB max
- SSR pour SEO optimal

#### üóÑÔ∏è PostgreSQL 16
- Port: 5432
- Optimis√© pour 32GB RAM:
  - Shared buffers: 4GB
  - Effective cache size: 16GB
  - Work mem: 256MB
- Persistent storage: `./data/postgres`

#### ‚ö° Redis 7
- Port: 6379
- Max memory: 2GB (allkeys-lru)
- Cache pour market data
- Persistent storage: `./data/redis`

#### üåê Caddy Reverse Proxy
- Ports: 80, 443, 8443
- HTTPS automatique (Let's Encrypt)
- HTTP/3 support
- Compression gzip/zstd
- Routes:
  - `/api/*` ‚Üí Backend
  - `/ws/*` ‚Üí Backend (WebSocket)
  - `/sse/*` ‚Üí Backend (Server-Sent Events)
  - `/*` ‚Üí Station (SvelteKit)

---

## Commandes utiles

### D√©marrage
```bash
# Production compl√®te
./deploy/setup-production.sh

# Cloudflare Tunnel
cloudflared tunnel run baconalgo

# Windows (auto-start au boot)
deploy\windows-startup.bat
```

### Monitoring
```bash
# Voir les logs en temps r√©el
docker compose -f docker-compose.production.yml logs -f

# Logs d'un service sp√©cifique
docker compose -f docker-compose.production.yml logs -f backend
docker compose -f docker-compose.production.yml logs -f station

# Statut des services
docker compose -f docker-compose.production.yml ps

# Health check manuel
./deploy/monitor.sh
```

### Maintenance
```bash
# Backup base de donn√©es
./deploy/backup.sh

# Red√©marrer un service
docker compose -f docker-compose.production.yml restart backend
docker compose -f docker-compose.production.yml restart station

# Red√©marrer tout
docker compose -f docker-compose.production.yml restart

# Arr√™ter
docker compose -f docker-compose.production.yml down

# Arr√™ter et supprimer les volumes (‚ö†Ô∏è DANGER)
docker compose -f docker-compose.production.yml down -v
```

### Mise √† jour
```bash
# Pull les derniers changements
git pull origin main

# Rebuild et red√©ployer
docker compose -f docker-compose.production.yml build
docker compose -f docker-compose.production.yml up -d

# Ou avec script
./deploy/setup-production.sh
```

---

## Monitoring & Alertes

### Health Check Automatique
```bash
# Ajouter au crontab (v√©rifie toutes les 5 minutes)
*/5 * * * * /chemin/vers/BaconAlgo/deploy/monitor.sh
```

### Discord Alerts
Configure `DISCORD_WEBHOOK_URL` dans `.env` pour recevoir des alertes automatiques si un service tombe.

### Logs
Les logs sont stock√©s dans `./logs/` et peuvent √™tre consult√©s via:
```bash
docker compose -f docker-compose.production.yml logs -f
```

---

## Capacit√© & Performance

### Charge support√©e
- **10,000-20,000 abonn√©s total**
- **1,500-3,000 utilisateurs simultan√©s**
- Scanner 10K+ instruments en parall√®le
- ML/LSTM sur RTX 4070 (12GB VRAM)

### Optimisations
- Cloudflare CDN devant (cache global)
- Cloudflare Tunnel (pas besoin d'ouvrir ports)
- Compression Brotli/gzip automatique
- HTTP/3 support
- Static assets cache 1 an
- PostgreSQL tun√© pour 7800X3D
- Redis LRU pour market data
- Rayon parallel scanner (16 threads)

---

## Cloudflare Tunnel

### Setup initial
```bash
./deploy/cloudflare-tunnel-setup.sh
```

### D√©marrer le tunnel
```bash
cloudflared tunnel run baconalgo
```

### Installer comme service (Linux/WSL2)
```bash
sudo cloudflared service install
sudo systemctl start cloudflared
sudo systemctl enable cloudflared
```

### Installer comme service (Windows)
```powershell
# PowerShell en Admin
cloudflared service install
sc start cloudflared
```

---

## Backup & Restore

### Backup automatique
```bash
./deploy/backup.sh
```

Backups stock√©s dans `./data/backups/`
- Nom: `baconalgo_YYYYMMDD_HHMMSS.sql.gz`
- R√©tention: 30 derniers backups

### Restore manuel
```bash
# Arr√™ter les services
docker compose -f docker-compose.production.yml down

# Restore depuis backup
gunzip -c ./data/backups/baconalgo_20240206_120000.sql.gz | \
  docker compose -f docker-compose.production.yml exec -T postgres \
  psql -U baconalgo baconalgo

# Red√©marrer
docker compose -f docker-compose.production.yml up -d
```

---

## S√©curit√©

### Firewall
- Cloudflare Tunnel = Pas besoin d'ouvrir ports
- Tous les services isol√©s dans Docker network
- HTTPS automatique via Caddy

### Variables sensibles
- **JAMAIS** commit `.env` dans git
- Utilise `.env.example` comme template
- Change tous les mots de passe par d√©faut

### Headers de s√©curit√©
Caddy ajoute automatiquement:
- `X-Content-Type-Options: nosniff`
- `X-Frame-Options: DENY`
- `Referrer-Policy: strict-origin-when-cross-origin`
- `Strict-Transport-Security: max-age=31536000`

---

## Troubleshooting

### Services ne d√©marrent pas
```bash
# Voir les logs d√©taill√©s
docker compose -f docker-compose.production.yml logs

# V√©rifier l'espace disque
df -h

# V√©rifier la RAM
free -h
```

### Backend ne r√©pond pas
```bash
# Voir les logs backend
docker compose -f docker-compose.production.yml logs backend

# Red√©marrer backend
docker compose -f docker-compose.production.yml restart backend

# V√©rifier health
curl http://localhost:8080/health
```

### Station ne charge pas
```bash
# Voir les logs station
docker compose -f docker-compose.production.yml logs station

# Rebuild station
docker compose -f docker-compose.production.yml build station
docker compose -f docker-compose.production.yml up -d station
```

### PostgreSQL slow
```bash
# Vacuum database
docker compose -f docker-compose.production.yml exec postgres \
  vacuumdb -U baconalgo -d baconalgo -z -v

# Voir les queries lentes
docker compose -f docker-compose.production.yml exec postgres \
  psql -U baconalgo -d baconalgo -c "SELECT * FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 10;"
```

### Redis m√©moire pleine
```bash
# V√©rifier m√©moire
docker compose -f docker-compose.production.yml exec redis redis-cli INFO memory

# Flush cache (‚ö†Ô∏è perte de donn√©es)
docker compose -f docker-compose.production.yml exec redis redis-cli FLUSHALL
```

---

## Support

### Contact
- **Email**: germain85@hotmail.com
- **Discord**: Voir `PUBLIC_DISCORD_URL` dans .env
- **YouTube**: Voir `PUBLIC_YOUTUBE_URL` dans .env

### Issues
Ouvre une issue sur GitHub: https://github.com/germain85ok/BaconAlgo/issues

---

## ü•ì Bon d√©ploiement!

**BaconAlgo** est maintenant pr√™t √† servir des milliers d'utilisateurs depuis ton PC Windows 11 avec Cloudflare Tunnel!

Pour toute question, consulte la documentation ou contacte le support.

**Made with ü•ì in Montr√©al**
